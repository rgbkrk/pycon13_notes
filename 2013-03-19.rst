Tue Mar 19 09:47:10 EDT 2013
============================

Yesterday I (lightly) participated in the sprints, spending some time getting django-deployer working with dotcloud (neither of which have I used before). Django-deployer tries to make deployments of django applications to multiple PaaS providers as easy as a few commands with a configuration file.

It's really too bad the PaaS providers don't have an interface that is common enough to all that configuration amongst all of them would be easy. Each has their own special sauce (Heroku for example puts STATIC_ROOT and MEDIA_ROOT stuffs in S3).

I also contributed some quick little changes to python-guide (grammar, spelling). I spent more time reading than editing. ;)

This morning I'm geared up and ready to go to PyData.

Tue Mar 19 12:03:49 EDT 2013
============================
Keynote of the morning was *the* Peter Norvig, the Director of Research at Google. His talk was titled "Learning Python".

He wrote "Artificial Intelligence: A Modern Approach"

Originally, all the code examples were lisp. He wanted to add something closer to pseudo-code. I think you can guess the final choice...

Benjamin Bloom's paper

"The average under tutoring [with mastery learning] was about 2 standard deviations above the average of the control." - Benjamin Bloom, 1984

2 minutes of AI learning

Massive classes

Analyzing Intro CS MOOC Data 101

His big idea:
We should do for syntax errors what Google does for search queries.

.. code:
       if x = 1:
            ^
   SyntaxError: invalid syntax

Should instead say:

.. code:
       if x = 1:
            ^
   SyntaxError: use == to check equality, = for assignment


Attractive Nuisance

Warnings for [[]]*5

# Premature optimization: code blocking I/O

He wrote a chaining class that forces functions that don't return the called object to return the object that called it... Hrmmm...

Why do students stay or go?

Motivation, not information

Willpower
Due dates
Peer support (forums, outside groups)
Faculty encouragement (email)
Pride of accomplishment
Authenticity
Early adopter


Stanford AI Course
Coursera course


ramp up + exponential decay + due dates

synchronous, evergreen, semi-synchronous, bus route

bus route -- cohort of students starting today
If something comes up, you can get off the bus and then hop back on that bus stop again.

Express bus, local bus.

Untrain the "if I put something wrong into the computer, the computer will error"
# This theme comes up all the freaking time with computer science. We need a cultural change.

TDD for teaching


Do we trust bloom?


Many types of Individualization
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Student control over rewind (multiplay)
Student choice over ...

Students shouldn't feel restricted from performing on the computer.

Transcripts are low bandwidth information on


I wonder if there are any large pseudo-anonymized data stores of (post-graduation) transcript grades

One-on-one tutoring, machine learning
large scale courseware engineering
social; motivation
machine learning, continual improvement

Data, privacy, and anonymization are recurring themes. How does one generate datasets we can reliably let others use without damning the individuals the data came from? It seems like there really isn't a way without losing a lot of the features that matter. People will always find ways to creatively point back to a user with enough aggregate information.



Tue Mar 19 13:26:18 EDT 2013
============================

Time for "Python in an evolving enterprise system"

Ad bidding in milliseconds

AppNexus has really evolved in the last few years.


Data-Driven Decisioning team


"Python enables us to scale our team and rapidly iterate and prototype technologies"


AppNexus sounds pretty awesome.

They built up a huge Hadoop cluster.

1PB Cluster
862 Nodes

I want these slides.

Definitely looking forward to all these talks going online.

Big Data: TBs/Hr
Medium Data: GBs/Hr


"*To enable the next generation* of data modeling, we need to leverage the Hadoop cluster"

Access the data on Hadoop

The budget problem
We have thousands of bidders buying billions of ads per hour in real time auctions.

We need to create a model that can manipulate how our bidders spend their budgets and purchase ads.

Someone is wearing a fragrance that is *hurting my nose and giving me a headache*. I'm going to steer clear of them throughout the conference.

Research: Potential Solutions for Python on Hadoop

.. role:: strike
    :class: strike

Native Java
Streaming - no framework
mrjob
Happy/Jython/PyCascading
Pig + Jython UDF
:strike: `Pydoop` prohibitive installation
:strike: `Disco evaluating` Hadoop
:strike: `Hadoopy / dumbo` similar to mrjob
:strike: `Hipy` Effectively ORM for Hive

Research: Criteria

Usability
Performance
Versatility/Flexibility

They go through all the frameworks and their benefits.


mrjob wraps Hadoop Streaming

PyCascading looks awesome
Python wrapper around Cascading framework for data processing workflow
Uses Jython as a high level ...

Yeeha

Onto Pig

Lots of similarities to cascading

Focus on data transformations

High level language is pig latin, compiles to a jar of map reduces

Question time
~~~~~~~~~~~~~

Can you do decision trees or clustering on Hadoop? (Mahout, etc.)



Tue Mar 19 14:10:51 EDT 2013
============================

Side note from Travis Oliphant:

You should not be using Jython, it blocks you from using Numpy and Pandas.

Use Py4J or ...
Tue Mar 19 17:10:22 EDT 2013

Blaze
~~~~~

"What we're pursuing with Blaze."
This is not a talk on what you can pursue tomorrow.

History of Numpy
~~~~~~~~~~~~~~~~
Matrix Object in Python -> Numeric -> Numarray -> NumPy

Hadoop still doesn't have the tools necessary for scientific computing

Numpy is the center of big community.

DATASETS ARE GROWING!!!

How do we do this while dealing with data across a network?

What's great about Numpy?
Array oriented
Extensive DType System (including systems)
- vs. Avro, Protobufs
C-API lots of libraries
Simple to understand data structure
Memory mapping
Syntax support from Python
Large community of users
Ufuncs and more
Broadcasting
Easy to interface C/C++/Fortran code


What is wrong with NumPy
Dtype system is difficult to extend
Immediate mode creates huge temporaries
Almost an in-memory data-base comparable to SQL-lite (missing indexes)
Integration with sparse arrays (SciPy slightly has this)
Lots of un-optimized parts
Minimal support for multi-core/GPU

Lots of improvements to NDArray needs to be made

Dtype improvements
Enumerated types
JSON to specify

Numpy + PyTables --> Blaze (out of Core, Distributed and Optimized NumPy)

Blaze is a new project to explore these ideas

"NumPy array is a decorated pointer"
# Sounds like a defined struct ;)

Blaze: Different kinds of Arrays

                               Indexable
              (Record Type)                (Primitive Type)
                NDTable                       NDArray
         Deferred     Concrete         Deferred     Concrete



Deferred allows handling large arrays

Can be handled out of core using chunks to stream through memory


Blaze Concrete Array
Data Descriptor (where are these bytes?)
URL, URL, URL, URL --> Indexes

DataShape
Extensible Type System which includes shape

MetaData
Dictionary



Multiple URLs comprising an array

Distributed Arrays (machines)

URLs provide bytes


Blaze data container

Indexes allow for many orderings (of access)


Advanced Types

  ...


Blaze Agents
CSV Directory
MongoDB


Hard scheduling problems, distribution problems


Tue Mar 19 16:19:50 EDT 2013
============================

The Hadoop file system (HDFS)
Large distributed file system
Thousands of nodes, PBs of data
Storage layer for Apache Hive, HBase

MapRedue
Idea: ship the code to the data not the other way around
Do aggregations locally
Iterate on results
Map phase: process the input records, emit a key & a value
Reduce phase: collect records with the same key from Map, emit a new (aggregate) record
Fault tolerance
Both storage and compute are fault tolerant (redundancy, replication, restart)



Hadoop in practice means...
Have to write Java
Have to translate problems to Map Reduce
Hard to maintain and make changes in the topology

Best used for
Archiving (HDFS)
Batch processing (MR)

Cascading in terms of flows

semi-structured flow processing of tuples with typed fields

Analogy: data is flowing in pipes
Input comes from source taps
Output goes to sink taps
Data is reshaped in the pipes by different operations

Builds a DAG from the job and optimizes the topology to minimize the number of MapReduce phases


PyCascading

cascading.org

This trip has been humbling.


PyCascading
Design
Built on top of Cascading
Uses the Jython 2.5 interpreter
Everything in Python
- Building the pipelines
- User-defined functions that operate on data
Completely hides Java if the user wants it to
- However...


WordCount example, as always

pycascading truly minimizes programmer effort

Basics of writing a cascading flow in Python

There is one main script that must contain a main() function
We build the pipeline in main()
Pipes are joined together with the pipe operator |
- Pipe ends may be assigned to variables and reused (split)
All the user defined operations are Python functions
- Globally or locally scoped
Then submit the pipeline to be run to PyCascading


  ...

http://www.cascading.org/documentation/
https://github.com/twitter/pycascading

The joins and field algebra are pretty neat.



Tue Mar 19 17:10:30 EDT 2013
============================

wise.io talk

wiseRF, machine learning, and Raspberry Pi

Python Bootcamps at Berkeley for Scientists and Students
# Neat!

ML in Python
scikit-learn for ML
pandas for data munging

ML pain points I
data scientists
- Data is messy
- Hard to scale non-linear algorithms to large datasets
- Ad-hoc feature engineering
- Collaboration on data, features and models is difficult


